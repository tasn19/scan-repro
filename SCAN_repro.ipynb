{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCAN-repro.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1xtaLtaf3Mm22T8YvkK-HSROeuHfbD4ox",
      "authorship_tag": "ABX9TyNxkfS+aK6faYILkStLGcUA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tasn19/scan-repro/blob/main/SCAN_repro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UMY85hvEe33"
      },
      "source": [
        "# Setup\n",
        "\n",
        "multiple sections or import .py into colab?\n",
        "\n",
        "Possible section structure\n",
        "1 Setup \n",
        " -> datasets\n",
        " -> model\n",
        " -> criterion\n",
        " -> utils\n",
        " 2 Pretext\n",
        " 3 SCAN\n",
        " 4 SelfLabel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GNygUzvZvT5"
      },
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrapCos_5Bfl"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Torchvision CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xio0wzq7oL2f"
      },
      "source": [
        "# Import dataset from torchvision\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/SCANmaterials/Unsupervised-Classification/datasets/cifar10\"\n",
        "dataset = torchvision.datasets.CIFAR10(root=path, transform=None, target_transform=None, download=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKR76ilXr_PQ"
      },
      "source": [
        "# retrieve image\n",
        "img, label = dataset.__getitem__(20)\n",
        "img.resize((64,64))\n",
        "print(img, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT4f0THquvJ4"
      },
      "source": [
        "img # Image.show() does not work on Colab!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29gn8TB8g7ht"
      },
      "source": [
        "Custom Dataset: contains a set of images and a set of the same images in augmented form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPXTSQ6hg6fj"
      },
      "source": [
        "# this is how they did it in the paper\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, dataset, step):\n",
        "    transform = dataset.transform\n",
        "    dataset.transform = None\n",
        "    self.dataset = dataset\n",
        "    self.step = step\n",
        "\n",
        "    if step == \"simclr\":\n",
        "      self.img_transform = base_transform\n",
        "      self.augment_transform = transform\n",
        "    else:\n",
        "      self.img_transform = base_transform\n",
        "      self.augment_transform = base_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    oriimg, label = self.dataset.__getitem__(index)\n",
        "    img = self.img_transform(oriimg)\n",
        "    augmented_img = self.augment_transform(oriimg)\n",
        "    return img, augmented_img, label\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92yn4KtCNetU"
      },
      "source": [
        "Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXeWwAR3Ey9D"
      },
      "source": [
        "# Create dictionary of transformation parameters (tp)\n",
        "tp = {\"base\": {\n",
        "    \"RandomResizedCrop\":{\"size\": 32},\n",
        "    \"Normalize\": {\"mean\": (0.4914, 0.4822, 0.4465), \"std\": (0.2023, 0.1994, 0.2010)}},\n",
        "    \"simclr\": {\n",
        "    \"RandomResizedCrop\":{\"size\": 32, \"scale\": (0.2, 1.0)},\n",
        "    \"RandomColorJitter\":{\"brightness\": 0.4, \"contrast\": 0.4, \"saturation\": 0.4, \"hue\": 0.1, \"p\": 0.8},\n",
        "    \"RandomGrayscale\":{\"p\": 0.2},\n",
        "    \"Normalize\": {\"mean\": (0.4914, 0.4822, 0.4465), \"std\": (0.2023, 0.1994, 0.2010)}}\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rEA8oFY__Cm"
      },
      "source": [
        "# Transformations to pre-process image  \n",
        "def get_transform(step):\n",
        "  # step options: 'base', 'simclr'\n",
        "  if step == \"base\":\n",
        "    transform = transforms.Compose([transforms.RandomResizedCrop(tp[step][\"RandomResizedCrop\"][\"size\"]),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(tp[step][\"Normalize\"][\"mean\"], tp[step][\"Normalize\"][\"std\"])]) \n",
        "\n",
        "  if step == \"simclr\": # what abt Gaussian blur ??\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.RandomResizedCrop(tp[step][\"RandomResizedCrop\"][\"size\"], tp[step][\"RandomResizedCrop\"][\"scale\"]),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomApply([\n",
        "            transforms.ColorJitter(tp[step][\"RandomColorJitter\"][\"brightness\"], tp[step][\"RandomColorJitter\"][\"contrast\"],\n",
        "                                  tp[step][\"RandomColorJitter\"][\"saturation\"], tp[step][\"RandomColorJitter\"][\"hue\"])], \n",
        "                                tp[step][\"RandomColorJitter\"][\"p\"]),\n",
        "        transforms.RandomGrayscale(tp[step][\"RandomGrayscale\"][\"p\"]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(tp[step][\"Normalize\"][\"mean\"], tp[step][\"Normalize\"][\"std\"])]\n",
        "    )\n",
        "  return transform\n",
        "\n",
        "  base_transform = get_transform(\"base\") # CIFAR10 dataset without CustomDataset should always use this?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67U8ehX1xW56"
      },
      "source": [
        "## Models\n",
        "\n",
        "ResNet-18 Backbone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWQAoX32xbey"
      },
      "source": [
        "# This is paper's version. Also used here: https://github.com/microsoft/snca.pytorch/blob/master/models/resnet_cifar.py\n",
        "# dfrnt from torchvision model, CHECK\n",
        "\"\"\"\n",
        "This code is based on the Torchvision repository, which was licensed under the BSD 3-Clause.\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, is_last=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.is_last = is_last\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        preact = out\n",
        "        out = F.relu(out)\n",
        "        if self.is_last:\n",
        "            return out, preact\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, is_last=False):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.is_last = is_last\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        preact = out\n",
        "        out = F.relu(out)\n",
        "        if self.is_last:\n",
        "            return out, preact\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, in_channel=3, zero_init_residual=False):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channel, 64, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves\n",
        "        # like an identity. This improves the model by 0.2~0.3% according to:\n",
        "        # https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for i in range(num_blocks):\n",
        "            stride = strides[i]\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        return out\n",
        "\n",
        "\n",
        "def resnet18a(**kwargs):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs) # changed\n",
        "    #return {'backbone': ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)} #, 'dim': 512}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhjSTil2LbyC"
      },
      "source": [
        "With SimLR contrastive model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JjyzA9lKEOQ"
      },
      "source": [
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "class SimclrContrastiveModel(nn.Module):\n",
        "  def __init__(self, backbone, head = 'MLP', featuresDim = 128, backboneDim = 512):\n",
        "    super(SimclrContrastiveModel, self).__init__() \n",
        "    self.backbone = backbone\n",
        "    self.backboneDim = backboneDim\n",
        "    self.head = head  # need? if linear not used, remove\n",
        "    # simCLR uses 2 layer MLP head \n",
        "    #nn.Linear(input sample size, output sample size)\n",
        "    #self.contrastiveHead = nn.Linear(self.backboneDim, featuresDim) # just for testing\n",
        "    self.contrastiveHead = nn.Sequential(nn.Linear(self.backboneDim, self.backboneDim),\n",
        "                                         nn.ReLU(), nn.Linear(self.backboneDim, featuresDim))\n",
        "  \n",
        "  def forward(self, x):\n",
        "      features = self.contrastiveHead(self.backbone(x))\n",
        "      features = F.normalize(features, dim = 1)\n",
        "      return features\n",
        "\n",
        "\n",
        "def get_model(step):\n",
        "  # Get backbone\n",
        "  #resnet18 = torchvision.models.resnet18(pretrained=False)  # what abt forward pass fnc in author code?\n",
        "  #resnet18_ft = nn.Sequential(*(list(resnet18.children())[0:9])) # remove last layer and retain feature extractor\n",
        "  #backbone = resnet18_ft\n",
        "  backbone = resnet18a()  \n",
        "\n",
        "  if step == \"simclr\":\n",
        "    # If pretext task, get simclr contrastive model\n",
        "    model = SimclrContrastiveModel(backbone)\n",
        "    # If scan or selflabel task, get clustering model\n",
        "    # will need to load pretrained weights for 2)scan & 3)selflabel\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz_zDG_P1YH6"
      },
      "source": [
        "## Criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tqKE-st-bmo"
      },
      "source": [
        "SimCLR Loss\n",
        "{Add loss fnc}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol5yQrtG1aTL"
      },
      "source": [
        "# loss_i,j = -log( exp(sim(z_i, z_j)/tau) / sum [1] exp(sim(z_i, z_k)/tau) )\n",
        "# Based on https://www.egnyte.com/blog/2020/07/understanding-simclr-a-framework-for-contrastive-learning/\n",
        "class SimCLR_loss(nn.Module):\n",
        "  def __init__(self, batch_size, temp=0.1):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size # need?\n",
        "    self.register_buffer(\"temperature\", torch.tensor(temp))\n",
        "    self.register_buffer(\"negatives_mask\", (~torch.eye(batch_size * 2, batch_size * 2, dtype=bool)).float())\n",
        "\n",
        "  def forward(self, emb_i, emb_j):\n",
        "    \"\"\"\n",
        "    emb_i and emb_j are batches of embeddings, where corresponding indices are pairs\n",
        "    z_i, z_j as per SimCLR paper\n",
        "    \"\"\"\n",
        "    z_i = F.normalize(emb_i, dim=1)\n",
        "    z_j = F.normalize(emb_j, dim=1)\n",
        "\n",
        "    representations = torch.cat([z_i, z_j], dim=0)\n",
        "    similarity_matrix = F.cosine_similarity(representations.unsqueeze(1), representations.unsqueeze(0), dim=2)\n",
        "  \n",
        "    sim_ij = torch.diag(similarity_matrix, self.batch_size)\n",
        "    sim_ji = torch.diag(similarity_matrix, -self.batch_size)\n",
        "    positives = torch.cat([sim_ij, sim_ji], dim=0)\n",
        "  \n",
        "    nominator = torch.exp(positives / self.temperature)\n",
        "    denominator = self.negatives_mask * torch.exp(similarity_matrix / self.temperature)\n",
        "    \n",
        "    loss_partial = -torch.log(nominator / torch.sum(denominator, dim=1))\n",
        "    loss = torch.sum(loss_partial) / (2 * self.batch_size)\n",
        "    print('NT-Xent loss', loss)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnzz6hZiDwrW"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QniZcZxPDyTL"
      },
      "source": [
        "# Determine 20 nearest neighbors with SimClR instance discrimination task\n",
        "def SimCLR_train(dataloader, model, epoch, criterion, optimizer):\n",
        "  # Record progress ADD\n",
        "  model.train()\n",
        "  for i, (ims, aug_ims, lbls) in enumerate(dataloader):\n",
        "    #print(ims.size())\n",
        "    batch, channel, h, w = ims.size()\n",
        "    x_i = ims.unsqueeze(1)\n",
        "    x_j = aug_ims.unsqueeze(1)    \n",
        "    x_i = x_i.view(-1, channel, h, w) # in model images processed independently so batch size doesn't matter \n",
        "    x_i = x_i.cuda(non_blocking=True)\n",
        "\n",
        "    x_j = x_j.view(-1, channel, h, w) \n",
        "    x_j = x_j.cuda(non_blocking=True)\n",
        "    targets = lbls.cuda(non_blocking=True) # need?\n",
        "    z_i = model(x_i) # try concatenation x_i and x_j?\n",
        "    z_j = model(x_j) \n",
        "    loss = criterion(z_i, z_j)\n",
        "    # update losses\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlI_fz_q8DYw"
      },
      "source": [
        "# Pretext Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Zf85p23BkK"
      },
      "source": [
        "# Pretext Task \n",
        "cifar_path = \"/content/drive/MyDrive/Colab Notebooks/SCANmaterials/Unsupervised-Classification/datasets/cifar10\"\n",
        "step = \"simclr\"\n",
        "transform = get_transform(\"simclr\")\n",
        "base_transform = get_transform(\"base\")\n",
        "\n",
        "# Dictionary containing hyperparameters\n",
        "# author code epochs = 500, batchsize = 512, num_workers = 8\n",
        "hyperparams = {\"epochs\": 10, \"batchsize\": 4, \"weight decay\": 0.0001, \"momentum\": 0.9, \"lr\": 0.4, \n",
        "                   \"lr decay rate\": 0.1, \"num_workers\": 2}\n",
        "\n",
        "# Load training set\n",
        "train1_set = CIFAR10(root = cifar_path, base_transform = base_transform, transform = transform, download = False) # change to True\n",
        "train_set = CustomDataset(train1_set, step)\n",
        "# enable pin_memory to speed up host to device transfer\n",
        "# Probably highest possible batch_size=128 & num_workers=2 with memory limits CHECK\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 128, shuffle = True, num_workers = 2, pin_memory = True)\n",
        "\n",
        "# Load testing set\n",
        "#test_set = CIFAR10(root = cifar_path, transform = transform, download = True)\n",
        "#test_loader = torch.utils.data.DataLoader(test_set, batch_size = 128, shuffle = True, num_workers = 2, pin_memory = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rxfs9wIXxwL"
      },
      "source": [
        "# For initial testing, take a small subset of dataset\n",
        "indices = torch.randperm(len(train_set)).tolist()\n",
        "expset = torch.utils.data.Subset(train_set, indices[:100])\n",
        "expload = torch.utils.data.DataLoader(expset, batch_size = 4, shuffle = True, num_workers = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYQIiMQ27-30"
      },
      "source": [
        "# Instantiate model\n",
        "model = get_model(step)\n",
        "model.cuda()\n",
        "\n",
        "# Get criterion\n",
        "batchsize = hyperparams[\"batchsize\"]\n",
        "criterion = SimCLR_loss(batchsize)\n",
        "criterion.cuda()\n",
        "\n",
        "lr = 0.4\n",
        "decay_rate = 0.1\n",
        "# Instantiate SGD (??) optimizer # original simclr paper used LARS...\n",
        "params = [p for p in model.parameters() if p.requires_grad] # CHECK\n",
        "optimizer = torch.optim.SGD(params, lr, momentum=hyperparams[\"momentum\"], \n",
        "                            weight_decay=hyperparams[\"weight decay\"], nesterov=False)\n",
        "\n",
        "# Train model\n",
        "# add warm-up? (to reduce effect of early training)\n",
        "epochs = hyperparams[\"epochs\"]\n",
        "for epoch in range(epochs):\n",
        "  print('Epoch ', epoch)\n",
        "  # Update scheduler (it resets every epoch)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=(lr*(decay_rate**3)))\n",
        "  lr = scheduler.get_lr()[0]\n",
        "  print('Learning Rate ', lr, len(scheduler.get_lr()))\n",
        "\n",
        "  # train\n",
        "  SimCLR_train(expload, model, epoch, criterion, optimizer)\n",
        "\n",
        "  # memory bank\n",
        "\n",
        "  # validate\n",
        "\n",
        "  # checkpoint\n",
        "\n",
        "  # update learning rate CHECK\n",
        "  scheduler.step()\n",
        "\n",
        "# Save model\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}